{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_Xception_TL.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/ghgh415263/Mal_dectection/blob/main/model_Xception_TL.ipynb",
      "authorship_tag": "ABX9TyP3P22LRicFbPHLozW4AHcW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghgh415263/Mal_dectection/blob/main/model_Xception_TL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0 input_2\n",
        "1 block1_conv1\n",
        "2 block1_conv1_bn\n",
        "3 block1_conv1_act\n",
        "4 block1_conv2\n",
        "5 block1_conv2_bn\n",
        "6 block1_conv2_act\n",
        "7 block2_sepconv1\n",
        "8 block2_sepconv1_bn\n",
        "9 block2_sepconv2_act\n",
        "10 block2_sepconv2\n",
        "11 block2_sepconv2_bn\n",
        "12 conv2d_4\n",
        "13 block2_pool\n",
        "14 batch_normalization_4\n",
        "15 add_12\n",
        "16 block3_sepconv1_act\n",
        "17 block3_sepconv1\n",
        "18 block3_sepconv1_bn\n",
        "19 block3_sepconv2_act\n",
        "20 block3_sepconv2\n",
        "21 block3_sepconv2_bn\n",
        "22 conv2d_5\n",
        "23 block3_pool\n",
        "24 batch_normalization_5\n",
        "25 add_13\n",
        "26 block4_sepconv1_act\n",
        "27 block4_sepconv1\n",
        "28 block4_sepconv1_bn\n",
        "29 block4_sepconv2_act\n",
        "30 block4_sepconv2\n",
        "31 block4_sepconv2_bn\n",
        "32 conv2d_6\n",
        "33 block4_pool\n",
        "34 batch_normalization_6\n",
        "35 add_14\n",
        "36 block5_sepconv1_act\n",
        "37 block5_sepconv1\n",
        "38 block5_sepconv1_bn\n",
        "39 block5_sepconv2_act\n",
        "40 block5_sepconv2\n",
        "41 block5_sepconv2_bn\n",
        "42 block5_sepconv3_act\n",
        "43 block5_sepconv3\n",
        "44 block5_sepconv3_bn\n",
        "45 add_15\n",
        "46 block6_sepconv1_act\n",
        "47 block6_sepconv1\n",
        "48 block6_sepconv1_bn\n",
        "49 block6_sepconv2_act\n",
        "50 block6_sepconv2\n",
        "51 block6_sepconv2_bn\n",
        "52 block6_sepconv3_act\n",
        "53 block6_sepconv3\n",
        "54 block6_sepconv3_bn\n",
        "55 add_16\n",
        "56 block7_sepconv1_act\n",
        "57 block7_sepconv1\n",
        "58 block7_sepconv1_bn\n",
        "59 block7_sepconv2_act\n",
        "60 block7_sepconv2\n",
        "61 block7_sepconv2_bn\n",
        "62 block7_sepconv3_act\n",
        "63 block7_sepconv3\n",
        "64 block7_sepconv3_bn\n",
        "65 add_17\n",
        "66 block8_sepconv1_act\n",
        "67 block8_sepconv1\n",
        "68 block8_sepconv1_bn\n",
        "69 block8_sepconv2_act\n",
        "70 block8_sepconv2\n",
        "71 block8_sepconv2_bn\n",
        "72 block8_sepconv3_act\n",
        "73 block8_sepconv3\n",
        "74 block8_sepconv3_bn\n",
        "75 add_18\n",
        "76 block9_sepconv1_act\n",
        "77 block9_sepconv1\n",
        "78 block9_sepconv1_bn\n",
        "79 block9_sepconv2_act\n",
        "80 block9_sepconv2\n",
        "81 block9_sepconv2_bn\n",
        "82 block9_sepconv3_act\n",
        "83 block9_sepconv3\n",
        "84 block9_sepconv3_bn\n",
        "85 add_19\n",
        "86 block10_sepconv1_act\n",
        "87 block10_sepconv1\n",
        "88 block10_sepconv1_bn\n",
        "89 block10_sepconv2_act\n",
        "90 block10_sepconv2\n",
        "91 block10_sepconv2_bn\n",
        "92 block10_sepconv3_act\n",
        "93 block10_sepconv3\n",
        "94 block10_sepconv3_bn\n",
        "95 add_20\n",
        "96 block11_sepconv1_act\n",
        "97 block11_sepconv1\n",
        "98 block11_sepconv1_bn\n",
        "99 block11_sepconv2_act\n",
        "100 block11_sepconv2\n",
        "101 block11_sepconv2_bn\n",
        "102 block11_sepconv3_act\n",
        "103 block11_sepconv3\n",
        "104 block11_sepconv3_bn\n",
        "105 add_21\n",
        "106 block12_sepconv1_act\n",
        "107 block12_sepconv1\n",
        "108 block12_sepconv1_bn\n",
        "109 block12_sepconv2_act\n",
        "110 block12_sepconv2\n",
        "111 block12_sepconv2_bn\n",
        "112 block12_sepconv3_act\n",
        "113 block12_sepconv3\n",
        "114 block12_sepconv3_bn\n",
        "115 add_22\n",
        "116 block13_sepconv1_act\n",
        "117 block13_sepconv1\n",
        "118 block13_sepconv1_bn\n",
        "119 block13_sepconv2_act\n",
        "120 block13_sepconv2\n",
        "121 block13_sepconv2_bn\n",
        "122 conv2d_7\n",
        "123 block13_pool\n",
        "124 batch_normalization_7\n",
        "125 add_23\n",
        "126 block14_sepconv1\n",
        "127 block14_sepconv1_bn\n",
        "128 block14_sepconv1_act\n",
        "129 block14_sepconv2\n",
        "130 block14_sepconv2_bn\n",
        "131 block14_sepconv2_act"
      ],
      "metadata": {
        "id": "4NWuW-2KTOU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/data/malimg_dataset.zip\" -d \"/content/dataset\""
      ],
      "metadata": {
        "id": "iIJB-0q6FCnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXiV41SdDKt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d4cfd9-8baf-4190-9476-74c05b40c0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9339 files belonging to 25 classes.\n",
            "Using 7472 files for training.\n",
            "Found 9339 files belonging to 25 classes.\n",
            "Using 1867 files for validation.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 299, 299, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 2048)              20861480  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 25)                51225     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,912,705\n",
            "Trainable params: 55,321\n",
            "Non-trainable params: 20,857,384\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "current decayed lr: 0.0010000\n",
            "Epoch 1/100\n",
            "59/59 [==============================] - 63s 820ms/step - loss: 1.0434 - accuracy: 0.7372 - val_loss: 0.7248 - val_accuracy: 0.8548\n",
            "current decayed lr: 0.0010000\n",
            "Epoch 2/100\n",
            "59/59 [==============================] - 49s 781ms/step - loss: 0.2622 - accuracy: 0.9344 - val_loss: 0.3247 - val_accuracy: 0.9245\n",
            "current decayed lr: 0.0010000\n",
            "Epoch 3/100\n",
            "59/59 [==============================] - 49s 782ms/step - loss: 0.1710 - accuracy: 0.9554 - val_loss: 0.1832 - val_accuracy: 0.9518\n",
            "current decayed lr: 0.0010000\n",
            "Epoch 4/100\n",
            "59/59 [==============================] - 49s 783ms/step - loss: 0.1337 - accuracy: 0.9609 - val_loss: 0.1268 - val_accuracy: 0.9614\n",
            "current decayed lr: 0.0010000\n",
            "Epoch 5/100\n",
            "59/59 [==============================] - 48s 777ms/step - loss: 0.1147 - accuracy: 0.9641 - val_loss: 0.0988 - val_accuracy: 0.9679\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "\n",
        "import pathlib\n",
        "\n",
        "class CustomCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "        current_decayed_lr = self.model.optimizer._decayed_lr(tf.float32).numpy()\n",
        "        print(\"current decayed lr: {:0.7f}\".format(current_decayed_lr))\n",
        "\n",
        "DATA_PATH = \"/content/dataset\"\n",
        "batch_size = 128\n",
        "img_height = 299\n",
        "img_width = 299\n",
        "val_split = 0.2\n",
        "interpolation = 'bicubic' #bicubic bilinear\n",
        "seed = 4885\n",
        "\n",
        "data_dir = pathlib.Path(DATA_PATH)\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=val_split,\n",
        "  color_mode='rgb',\n",
        "  interpolation=interpolation,\n",
        "  subset=\"training\",\n",
        "  seed=seed,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=val_split,\n",
        "  color_mode='rgb',\n",
        "  interpolation=interpolation,\n",
        "  subset=\"validation\",\n",
        "  seed=seed,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "base_model = Xception(weights=\"imagenet\", include_top=False, input_shape=(img_height,img_width,3), pooling=\"avg\") #pooling=\"avg\"\n",
        "for layer in base_model.layers[:130]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "    base_model,\n",
        "    keras.layers.Dropout(0.7),\n",
        "    layers.Dense(25, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=2340,\n",
        "    decay_rate=0.2,\n",
        "    staircase=False) #staircase=False\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/Colab_Notebooks/save/exception-1layer/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "#model.load_weights(\"/content/drive/MyDrive/Colab_Notebooks/save/exception-1layer/cp-0100.ckpt\")\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch > 25:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.15)\n",
        "\n",
        "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=25)\n",
        "\n",
        "history = model.fit(train_ds, epochs=100, initial_epoch=0, validation_data=val_ds, callbacks=[cp_callback, CustomCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_test = np.array([])\n",
        "y_pred = np.array([])\n",
        "\n",
        "for x,y in val_ds:\n",
        "  y_test = np.append(y_test, y.numpy(), axis=0)\n",
        "  tmp = (model.predict(x)).argmax(axis=-1)\n",
        "  y_pred = np.append(y_pred, tmp, axis=0)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=val_ds.class_names)\n",
        "fig, ax = plt.subplots(figsize=(16,16))\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cHXrerX3E_Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(epochs, loss, 'ro-', label='Training loss', markersize = 4)\n",
        "plt.plot(epochs, val_loss, 'bo-', label='Validation loss', markersize = 4)\n",
        "plt.title('Training and validation loss', fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.legend(fontsize=14)\n",
        "plt.xticks(range(len(acc) + 1), range(len(acc) + 1))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fBmi7VC0FHRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.clf()   # 그림을 초기화합니다\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(epochs, acc, 'ro-', label='Training acc', markersize = 4)\n",
        "plt.plot(epochs, val_acc, 'bo-', label='Validation acc', markersize = 4)\n",
        "plt.title('Training and validation accuracy', fontsize=14)\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.legend(fontsize=14)\n",
        "plt.xticks(range(len(acc) + 1), range(len(acc) + 1))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jRSWEq4TFID4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"%-8s\" % \"epoch\", \"%-23s\" % \"train_loss\", \"%-23s\" % \"val_loss\", \"%-23s\" % \"train_acc\", \"%-23s\" % \"val_acc\")\n",
        "print(\"=\" * 99)\n",
        "for i in range(1,len(acc)+1):\n",
        "        print(\"%-8s\" %i, \"%-23s\" % loss[i-1], \"%-23s\" % val_loss[i-1], \"%-23s\" % acc[i-1], \"%-23s\" % val_acc[i-1])"
      ],
      "metadata": {
        "id": "7yGGDua3FL_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}